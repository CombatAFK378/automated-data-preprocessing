import pandas as pd
import numpy as np
import os

def clean_data(file_path):
    print(f"--- Starting Data Cleaning: {file_path} ---")
    
    # 1. Load Data
    if not os.path.exists(file_path):
        return "Error: File not found."
        
    try:
        if file_path.endswith('.csv'):
            df = pd.read_csv(file_path)
        elif file_path.endswith(('.xls', '.xlsx')):
            df = pd.read_excel(file_path, sheet_name=0) 
        else:
            return "Error: Unsupported format (use CSV or Excel)"
    except Exception as e:
        return f"Error loading file: {e}"
    
    print(f"Original Shape: {df.shape}")
    
    # 2. Drop completely empty rows/columns
    df.dropna(how='all', axis=0, inplace=True)
    df.dropna(how='all', axis=1, inplace=True)
    
    # 3. Standardize column names
    df.columns = (df.columns.str.strip()
                            .str.lower()
                            .str.replace(' ', '_')
                            .str.replace(r'[^\w]', '', regex=True))  # ✅ FIXED
    
    # 4. Remove duplicates
    df.drop_duplicates(inplace=True)
    
    # 5. Strip whitespace from string columns
    str_cols = df.select_dtypes(include=['object']).columns
    for col in str_cols:
        df[col] = df[col].map(lambda x: x.strip() if isinstance(x, str) else x)
    
    # 6. Handle Missing Values
    numeric_cols = df.select_dtypes(include=['number']).columns
    for col in numeric_cols:
        if df[col].isnull().any():
            median_val = df[col].median()
            df[col] = df[col].fillna(median_val)
            print(f"Filled '{col}' missing values with median: {median_val:.2f}")
    
    cat_cols = df.select_dtypes(include=['object']).columns
    for col in cat_cols:
        if df[col].isnull().any():
            df[col] = df[col].fillna("Unknown")
            print(f"Filled '{col}' missing values with 'Unknown'")
    
    # 7. Try numeric conversion
    for col in cat_cols:
        try:
            if df[col].str.contains(r'\d', regex=True).any():  # ✅ Also fixed here (single backslash)
                cleaned = df[col].astype(str).str.replace(r'[$,%]', '', regex=True)
                converted = pd.to_numeric(cleaned, errors='coerce')
                
                if converted.notna().mean() > 0.5:
                    df[col] = converted
                    print(f"Converted '{col}' to numeric")
        except:
            pass
    
    # 8. Try datetime conversion
    obj_cols = df.select_dtypes(include=['object']).columns 
    for col in obj_cols:
        try:
            converted = pd.to_datetime(df[col], errors='coerce')
            if converted.notna().mean() > 0.4:
                df[col] = converted
                print(f"Converted '{col}' to datetime")
        except:
            pass
    
    print(f"--- Cleaned Shape: {df.shape} ---")
    return df







1. The "Sheet 2" Trap
Scenario: The Excel file loads, but the columns are weird or empty. The Cause: Corporate Excel files often have an "Instructions" or "Disclaimer" tab as Sheet 1. Your data is actually on Sheet 2. The Fix: If df.shape looks wrong, change this line immediately:

Python
# Change sheet_name=0 to sheet_name='Sheet2' or the actual name
df = pd.read_excel(file_path, sheet_name='Data_Sheet_Name') 
2. The "Double Header" Trap
Scenario: The column names look like Unnamed: 0, Unnamed: 1, and the actual headers are in Row 2 or 3. The Cause: The file has a title or logo at the top before the actual table starts. The Fix: Add the header or skiprows parameter:

Python
# Skip the first 2 rows to find the real header
df = pd.read_excel(file_path, skiprows=2)
3. The "Encoding" Error (CSV Only)
Scenario: You try to load a CSV and get a crash: UnicodeDecodeError. The Cause: The file was saved in an older format (common in banks/insurance companies). The Fix: Update your read_csv line to try a different encoding:

Python
# Try 'latin1' or 'cp1252' if utf-8 fails
df = pd.read_csv(file_path, encoding='latin1')





The "Analysis" Cheat Sheet (Add this to your Repo)
1. The "Group By" Snippet (Most Common Question)
Question: "Calculate the average/sum/count of X per Y."

Code:

Python
def get_group_stats(df, group_col, target_col):
    # "Group by Region, give me sum of Sales and count of Orders"
    return df.groupby(group_col)[target_col].agg(['sum', 'mean', 'count']).reset_index()
2. The "Pivot Table" Snippet (The "Excel" Question)
Question: "Make a table where rows are Students, columns are Subjects, and values are Marks."

Code:

Python
def make_pivot(df, index_col, columns_col, values_col):
    # Useful for reshaping data
    return df.pivot_table(index=index_col, columns=columns_col, values=values_col, aggfunc='sum').fillna(0)
3. The "Date Logic" Snippet
Question: "How many sales happened in the last 7 days?" or "Extract the Month from the date."

Code:

Python
def add_date_features(df, date_col):
    # Extract Month, Year, Day of Week
    df['Month'] = df[date_col].dt.month_name()
    df['Year'] = df[date_col].dt.year
    df['DayOfWeek'] = df[date_col].dt.day_name()
    return df
